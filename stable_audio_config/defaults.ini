[DEFAULTS]

lora_config = "stable_audio_config/lora_config.json"
#name of the run
name = stable_audio_tools

# parameters need to be changed every exp
batch_size = 35
max_epochs = 50
iter = 1
filter_threshold = 95
object_name = ceramic_mug
scene_name = 0118_bathroom

# dataset config path
dataset_config = 'stable_audio_config/dataset_config.json'

# number of GPUs to use for training
num_gpus = 1

# number of nodes to use for training
num_nodes = 1 

# Precision to use for training
precision = "16-mixed"

# number of CPU workers for the DataLoader
num_workers = 8

# the random seed
seed = 1102

# Batches for gradient accumulation
accum_batches = 1

# Number of steps between checkpoints
checkpoint_every = 50                              

# trainer checkpoint file to restart training from
ckpt_path = ''

# model checkpoint file to start a new training run from
pretrained_ckpt_path = ''

# Checkpoint path for the pretransform model if needed
pretransform_ckpt_path = ''

# configuration model specifying model hyperparameters
model_config = 'stable_audio_config/model_config.json'

# directory to save the checkpoints in
save_dir = 'logs'

# gradient_clip_val passed into PyTorch Lightning Trainer
gradient_clip_val = 0.0

# remove the weight norm from the pretransform model
remove_pretransform_weight_norm = ''

# whether to use LoRA or not
use_lora = 'true'

# checkpoint path for the lora model if needed
lora_ckpt_path = ''

# number of steps between ReLoRA updates
relora_every = 0

# experimental quantization for qlora
quantize = 'false'